{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"Intro Projects Blogs Skills About Me Contact","tags":["Welcome"]},{"location":"#welcome","title":"Hey there Hello..! Welcome to my Portfolio","text":"","tags":["Welcome"]},{"location":"#intro","title":"Hi, I'm Sunil Sharma","text":"<p>             I\u2019m a passionate Python Developer and Data Scientist who loves crafting innovative solutions and sharing my journey through engaging stories.         </p>","tags":["Welcome"]},{"location":"#explore","title":"&gt;&gt; I'm thrilled to have you here. Explore my projects, read my blogs, and get to know more about me. &lt;&lt;","text":"","tags":["Welcome"]},{"location":"#projects","title":"Featured Projects","text":"<p>Discover innovative projects where technology meets creativity.</p> S3-faker <p>Create fake Data and store in aws s3 bucket (localstack)</p> paraxcel <p>Convert docx to excel sheet</p> S3-faker <p>Create fake Data and store in aws s3 bucket (localstack)</p> paraxcel <p>Convert docx to excel sheet</p> Explore Projects","tags":["Welcome"]},{"location":"#blogs","title":"Featured Blogs","text":"<p>Read my latest insights on development, data science, and tech trends.</p> blog 1 title <p>Short description of the project.</p> blog 2 title <p>Short description of the project.</p> blog 1 title <p>Short description of the project.</p> blog 2 title <p>Short description of the project.</p> Read Blogs","tags":["Welcome"]},{"location":"#skills","title":"Skills &amp; Expertise","text":"<p>Continuously expanding my technical horizons</p> Programming Languages <p>                     Python,                     JavaScript,                     SQL                 </p> Data Science <p>                     Machine Learning,                     Data Visualization,                     Statistical Analysis                 </p> Frameworks &amp; Libraries <p>                     React,                     TensorFlow,                     Pandas                 </p> Tools &amp; Technologies <p>                     Git,                     Docker,                     AWS                 </p>","tags":["Welcome"]},{"location":"#about","title":"About Me","text":"<p>Learn more about my journey, skills, and experiences in tech.</p>                  Download Resume                            Get to Know Me","tags":["Welcome"]},{"location":"#contact","title":"Let's Connect","text":"<p>Have a question or a collaboration idea? Let's connect!</p>                  GitHub                               LinkedIn                           More Ways to Connect","tags":["Welcome"]},{"location":"about/","title":"About Me","text":"<p>Hi, I'm Sunil Sharma, a passionate Python Developer and Data Scientist. I specialize in creating innovative solutions and sharing my knowledge through blogs. With a strong background in data analysis and machine learning, I strive to turn data into actionable insights.</p>"},{"location":"about/#resumecv","title":"Resume/CV","text":"Resume"},{"location":"about/#my-journey","title":"My Journey","text":""},{"location":"about/#education","title":"Education","text":"<ul> <li>Degree: Bachelor's in Computer Science<ul> <li>University: Devi Ahilyabai Vishav Vidhyalay(DAVV), Indore</li> <li>Collage: PMB Gujarati Science College, Indore</li> <li>2015-2018</li> </ul> </li> </ul>"},{"location":"about/#experience","title":"Experience","text":"<p>I have worked on various projects involving data analysis, machine learning, and web development. My goal is to leverage my skills to solve real-world problems and contribute to the tech community.</p> <ul> <li> <p>Hackathon</p> <ul> <li>GSTN Hackathon | 2024</li> <li>Developing a Binary Classification model on highly annonymised data.</li> </ul> </li> <li> <p>Academic Project</p> <ul> <li>Company Name | Dates</li> <li>Describe your role and responsibilities.</li> </ul> </li> </ul>"},{"location":"about/#explore","title":"Explore","text":"More Projects       More Blogs"},{"location":"about/#skills","title":"Skills","text":"<ul> <li>Python, JavaScript, HTML, CSS</li> <li>Data Analysis (Numpy, pandas)</li> <li>Machine Learning (Scikit-Learn, XGBoost)</li> <li>Web Development (Flask, Django, Fastapi)</li> <li>Data Visualization (Matplotlib, Seaborn)</li> <li>Web Scrapping (BeautifulSoup, Selenium)</li> <li>Ai &amp; Agentic space:<ul> <li>Mistralai, Gemini</li> <li>Langchain, Langgraph</li> <li>Huggingface</li> </ul> </li> <li>Database:<ul> <li><code>SQL</code>: Sql, MySql, Postgresql</li> <li><code>NoSQL</code>: MongoDB, Redis</li> </ul> </li> </ul>"},{"location":"about/#tools-dev-ops","title":"Tools &amp; Dev-Ops","text":"<ul> <li>Tools: VSCode, Notebook, Git, Github, Docker, Kubernetes</li> <li>OS: Windows, Linux</li> <li>cloud: AWS, Azure, GCP</li> </ul>"},{"location":"about/#hobbies-interests","title":"Hobbies &amp; Interests","text":"<ul> <li>Coding</li> <li>Blogging</li> <li>Reading</li> </ul>"},{"location":"contact/","title":"Contact","text":"<p>Feel free to reach out to me for any inquiries or collaborations.</p>"},{"location":"contact/#email","title":"Email","text":"<p>  Email </p>"},{"location":"contact/#social-links","title":"Social Links","text":"LinkedIn       GitHub       DockerHub       Twitter"},{"location":"resume/","title":"Resume/CV","text":""},{"location":"resume/#download-my-resumecv","title":"Download my Resume/CV","text":"Resume"},{"location":"resume/#know-more-about-me","title":"Know more about me","text":"Know More"},{"location":"tags/","title":"Tags","text":"<p>Following is a list of relevant tags:</p>"},{"location":"tags/#tag:welcome","title":"Welcome","text":"<ul> <li>            Welcome          </li> </ul>"},{"location":"blog/","title":"Blogs","text":"<p>Welcome to my blog! Here you will find my latest posts and updates.</p>"},{"location":"blog/#featured","title":"Featured","text":""},{"location":"blog/#blog-1","title":"Blog 1","text":"<p>Short excerpt or description of the post.</p>"},{"location":"blog/#blog-2","title":"Blog 2","text":"<p>Short excerpt or description of the post.</p>"},{"location":"blog/#latest-blogs","title":"Latest Blogs","text":""},{"location":"blog/#blog-1-latest","title":"Blog 1 - latest","text":""},{"location":"blog/#blog-2-latest","title":"Blog 2 - latest","text":""},{"location":"blog/2023/12/31/happy-new-years-eve/","title":"Happy new years eve!","text":"<p>We hope you are all having fun and wish you all the best for the new year!</p> <p>some content healjhdlkjaks;khalkhsl some content healjhdlkjaks;khalkhsl some content healjhdlkjaks;khalkhsl some content healjhdlkjaks;khalkhsl</p>"},{"location":"blog/2023/12/31/happy-new-years-eve/","title":"Happy new years eve","text":"<p>We hope you are all having fun and wish you all the best for the new year!</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>"},{"location":"projects/","title":"Projects","text":"<p>Here are some of my notable projects:</p>"},{"location":"projects/#s3-faker-fake-data-generator","title":"s3 faker - Fake data generator","text":"<p>Fake data generation and storing with s3.</p>"},{"location":"projects/#webscraper-hunt-jobs","title":"webscraper - Hunt Jobs","text":"<p>Using Webscraper to Hunt Jobs.</p>"},{"location":"projects/#paraxcel-convert-docx-to-excel","title":"paraxcel - Convert docx to excel","text":"<p>Converting docx to excel.</p>"},{"location":"projects/naukari-webscraper/","title":"Job Listings Web Scraper","text":""},{"location":"projects/naukari-webscraper/#overview","title":"Overview","text":"<p>Job Listings Web Scraper is a Python script that scrapes job listings from Naukri.com and allows users to filter and analyze them based on skills. The project aims to help users find job listings efficiently by allowing them to search, filter, and save job data in a structured format.</p>"},{"location":"projects/naukari-webscraper/#responsibilities","title":"Responsibilities","text":"<ul> <li>Developed the core script for web scraping job listings from Naukri.com.</li> <li>Implemented data filtering and analysis functionalities.</li> <li>Ensured the project adhered to best practices in terms of performance and usability.</li> <li>Wrote and maintained comprehensive documentation and unit tests.</li> </ul>"},{"location":"projects/naukari-webscraper/#technologies-used","title":"Technologies Used","text":"<ul> <li>Languages: Python</li> <li>Libraries/Frameworks: Selenium, Pandas</li> <li>Tools: Git, VS Code</li> </ul>"},{"location":"projects/naukari-webscraper/#challenges-and-solutions","title":"Challenges and Solutions","text":"<ul> <li>Challenge: Handling dynamic content on Naukri.com.</li> <li>Solution: Utilized Selenium to navigate and interact with the web pages dynamically.</li> <li>Challenge: Ensuring data accuracy and completeness.</li> <li>Solution: Implemented robust error handling and data validation mechanisms.</li> </ul>"},{"location":"projects/naukari-webscraper/#achievements","title":"Achievements","text":"<ul> <li>Successfully created a script that can scrape and filter job listings based on user-defined criteria.</li> <li>Integrated data export functionality to save job listings in CSV format.</li> <li>Received positive feedback for the script's usability and effectiveness.</li> </ul>"},{"location":"projects/naukari-webscraper/#key-learnings","title":"Key Learnings","text":"<ul> <li>Gained experience in web scraping with Selenium.</li> <li>Enhanced skills in data processing and analysis using Pandas.</li> <li>Improved understanding of user interaction and input handling in Python scripts.</li> </ul>"},{"location":"projects/naukari-webscraper/#link-to-project","title":"Link to Project","text":"<ul> <li>GitHub Repository</li> </ul>"},{"location":"projects/naukari-webscraper/#screenshots","title":"Screenshots","text":""},{"location":"projects/paraxcel/","title":"Paraxcel","text":""},{"location":"projects/paraxcel/#overview","title":"Overview","text":"<p>Paraxcel is a Python-based project designed to enhance data processing and analysis capabilities using Excel files. The main goal of this project is to provide a streamlined and efficient way to manipulate, analyze, and visualize data directly from Excel spreadsheets. Key features include data extraction, transformation, and visualization, all within a Python environment.</p>"},{"location":"projects/paraxcel/#responsibilities","title":"Responsibilities","text":"<ul> <li>Designed and implemented core functionalities for data extraction and transformation from Excel files.</li> <li>Developed modules for data visualization, enabling users to create charts and graphs directly from spreadsheet data.</li> <li>Ensured the project adhered to best practices in terms of code quality, performance, and security.</li> <li>Coordinated with team members to gather requirements and provide technical guidance.</li> <li>Wrote and maintained comprehensive documentation to help users get started and effectively utilize the project.</li> </ul>"},{"location":"projects/paraxcel/#technologies-used","title":"Technologies Used","text":"<ul> <li>Languages: Python</li> <li>Libraries/Frameworks: Pandas, Openpyxl, Matplotlib, Seaborn</li> <li>Tools: Git, Jupyter Notebooks, VS Code</li> </ul>"},{"location":"projects/paraxcel/#challenges-and-solutions","title":"Challenges and Solutions","text":"<ul> <li>Challenge: Handling large Excel files efficiently.</li> <li>Solution: Optimized data processing algorithms and utilized efficient data structures to manage memory usage and processing time.</li> <li>Challenge: Ensuring compatibility with various versions and formats of Excel files.</li> <li>Solution: Conducted extensive testing with different Excel file versions and formats, and implemented robust error handling to manage discrepancies.</li> </ul>"},{"location":"projects/paraxcel/#achievements","title":"Achievements","text":"<ul> <li>Successfully created a versatile tool that simplifies data manipulation and analysis for Excel files.</li> <li>Integrated advanced data visualization capabilities, allowing users to generate insightful charts and graphs with ease.</li> <li>Received positive feedback from users for the project's ease of use and comprehensive documentation.</li> </ul>"},{"location":"projects/paraxcel/#key-learnings","title":"Key Learnings","text":"<ul> <li>Gained in-depth knowledge of data manipulation and analysis using Python.</li> <li>Enhanced skills in data visualization and learned best practices for creating informative and aesthetically pleasing charts.</li> <li>Improved understanding of Excel file formats and the challenges associated with handling large datasets.</li> <li>Learned the importance of thorough testing and documentation in ensuring project success.</li> </ul>"},{"location":"projects/paraxcel/#link-to-project","title":"Link to Project","text":"<ul> <li>GitHub Repository</li> </ul>"},{"location":"projects/paraxcel/#screenshots","title":"Screenshots","text":""},{"location":"projects/s3-faker/","title":"S3 Faker","text":"<p>S3 Faker is a tool designed to generate fake data based on a JSON configuration file. The generated data can be saved locally and also uploaded to an AWS S3 bucket. This project is ideal for testing and development purposes, allowing developers to simulate S3 environments without the need for actual AWS resources. Key features include data generation using the Faker library, support for multiple output formats (CSV, JSON, Parquet), and integration with AWS S3 via s3fs.</p>"},{"location":"projects/s3-faker/#responsibilities","title":"Responsibilities","text":"<ul> <li>Designed and implemented the core functionalities of the S3 Faker project.</li> <li>Developed scripts and modules to accurately simulate S3 behavior.</li> <li>Led the integration of the project with existing development and testing pipelines.</li> <li>Ensured the project adhered to best practices in terms of security and performance.</li> <li>Coordinated with team members to gather requirements and provide technical guidance.</li> </ul>"},{"location":"projects/s3-faker/#technologies-used","title":"Technologies Used","text":"<ul> <li>Languages: Python, PowerShell, Shell</li> <li>Frameworks/Libraries: Faker, Pandas, fsspec</li> <li>Tools: Git, Docker, LocalStack, AWS CLI</li> </ul>"},{"location":"projects/s3-faker/#challenges-and-solutions","title":"Challenges and Solutions","text":"<ul> <li>Challenge: Simulating the comprehensive feature set of Amazon S3, including edge cases.</li> <li>Solution: Conducted extensive research on S3 APIs and utilized <code>fsspec</code> to implement accurate simulations. Developed custom scripts to handle edge cases and ensure robustness.</li> <li>Challenge: Ensuring performance and scalability of the local S3 environment.</li> <li>Solution: Optimized code and utilized Docker for containerization, allowing for scalable and isolated testing environments.</li> </ul>"},{"location":"projects/s3-faker/#achievements","title":"Achievements","text":"<ul> <li>Successfully created a fully functional S3 simulation environment, reducing reliance on actual S3 resources by 80%.</li> <li>Integrated the project with CI/CD pipelines, significantly speeding up the development and testing cycles.</li> <li>Received positive feedback from team members and external testers for the accuracy and reliability of the simulation.</li> </ul>"},{"location":"projects/s3-faker/#key-learnings","title":"Key Learnings","text":"<ul> <li>Gained in-depth knowledge of Amazon S3 APIs and their intricacies.</li> <li>Enhanced skills in Python and PowerShell scripting.</li> <li>Improved understanding of containerization and its benefits in development and testing environments.</li> <li>Learned the importance of thorough testing and documentation in ensuring project success.</li> </ul>"},{"location":"projects/s3-faker/#link-to-project","title":"Link to Project","text":"<ul> <li>GitHub Repository</li> </ul>"},{"location":"projects/s3-faker/#screenshots","title":"Screenshots","text":""},{"location":"blog/archive/2023/","title":"2023","text":""}]}